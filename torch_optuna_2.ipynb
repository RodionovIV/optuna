{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ce59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import transformers as ppb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f890777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(obj, filename):\n",
    "    with open(f\"{filename}.pkl\", mode=\"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(f\"{filename}.pkl\", mode=\"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "        return obj\n",
    "\n",
    "test_obj = [1,2,3]\n",
    "test_filename=\"test\"\n",
    "try:\n",
    "    save_pickle(test_obj, test_filename)\n",
    "    test_load = load_pickle(test_filename)\n",
    "    assert test_obj==test_load, \"TEST\"\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdba1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "def create_dataloader(embeddings, labels, batch_size=1):\n",
    "    dataset = ClassifierDataset(embeddings, labels)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd19a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_data = load_pickle(\"train_data\")\n",
    "    test_data = load_pickle(\"test_data\")\n",
    "    X_train, y_train = train_data[\"embeddings\"], train_data[\"labels\"]\n",
    "    X_test, y_test = test_data[\"embeddings\"], test_data[\"labels\"]\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17ac3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_dataloader(X_train, y_train, batch_size=64)\n",
    "test = create_dataloader(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1481518",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40503794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(768, n_classes)\n",
    "        self.silu = torch.nn.SiLU()\n",
    "#         self.opt = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "#         self.device = device\n",
    "#         self.criteria = torch.nn.CrossEntropyLoss()\n",
    "#         self.epochs = n_epochs\n",
    "#         self.to(device)\n",
    "    def forward(self, embeddings):\n",
    "        outputs=self.l1(embeddings)\n",
    "        return outputs\n",
    "    \n",
    "#     def train_step(self, train):\n",
    "#         for batch in train:\n",
    "#             X, y = batch\n",
    "#             X = X.to(self.device)\n",
    "#             y = y.to(self.device)\n",
    "#             logits = self(X)\n",
    "#             loss=self.criteria(logits, y)\n",
    "#             self.opt.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.opt.step()\n",
    "    \n",
    "#     def eval_step(self, test):\n",
    "#         for batch in test:\n",
    "#             X, y = batch\n",
    "#             X = X.to(self.device)\n",
    "#             y = y.to(self.device)\n",
    "#             logits = self(X)\n",
    "#             loss=self.criteria(logits, y)\n",
    "#             self.opt.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.opt.step()\n",
    "        \n",
    "    \n",
    "#     def fit(self, train):\n",
    "#         self.train()\n",
    "#         for epoch in range(self.epochs):\n",
    "#             self.train_step(train)\n",
    "    \n",
    "#     def predict(self, test):\n",
    "#         self.eval()\n",
    "#         with torch.no_grad():\n",
    "#             probas, labels = [], []\n",
    "#             softmax = torch.nn.Softmax(dim=-1)\n",
    "#             for X in test:\n",
    "#                 X = torch.FloatTensor(X).to(self.device)\n",
    "#                 score = self(X)\n",
    "#                 proba = softmax(score)[1].item()\n",
    "#                 probas.append(proba)\n",
    "#                 label = torch.argmax(score).item()\n",
    "#                 labels.append(label)\n",
    "#         return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c558bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optuna example that optimizes multi-layer perceptrons using PyTorch.\n",
    "\n",
    "In this example, we optimize the validation accuracy of fashion product recognition using\n",
    "PyTorch and FashionMNIST. We optimize the neural network architecture as well as the optimizer\n",
    "configuration. As it is too time consuming to use the whole FashionMNIST dataset,\n",
    "we here use a small subset of it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    device=\"cpu\"\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    #optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-4, 1e-1) \n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 5, 100)\n",
    "    \n",
    "    model = Classifier()\n",
    "    model.to(device)\n",
    "    criteria = torch.nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for batch in train:\n",
    "            X, y = batch\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(X)\n",
    "            loss = criteria(logits, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            labels, probas = [], []\n",
    "            for batch in test:\n",
    "                X, y = batch\n",
    "                X = X.to(device)\n",
    "                logits = model(X)\n",
    "                proba = softmax(logits)[:,1].tolist()\n",
    "                labels += y.tolist()\n",
    "                probas += proba\n",
    "            \n",
    "            roc_score = roc_auc_score(labels, probas)\n",
    "            \n",
    "            trial.report(roc_score, epoch)\n",
    "\n",
    "            # Handle pruning based on the intermediate value.\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fd57afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-13 01:10:10,155] A new study created in memory with name: no-name-b408585b-f66d-4ac6-bd71-833d1bf03a82\n",
      "[I 2023-07-13 01:10:13,992] Trial 0 finished with value: 0.8991090652013238 and parameters: {'lr': 0.005517622283844181, 'weight_decay': 0.0421665236511578, 'n_epochs': 68}. Best is trial 0 with value: 0.8991090652013238.\n",
      "[I 2023-07-13 01:10:17,638] Trial 1 finished with value: 0.8948164036976336 and parameters: {'lr': 0.00032389092301081585, 'weight_decay': 0.05879814088541134, 'n_epochs': 65}. Best is trial 0 with value: 0.8991090652013238.\n",
      "[I 2023-07-13 01:10:19,589] Trial 2 finished with value: 0.8889062951894341 and parameters: {'lr': 0.0003197993007051008, 'weight_decay': 0.09536832899788185, 'n_epochs': 33}. Best is trial 0 with value: 0.8991090652013238.\n",
      "[I 2023-07-13 01:10:21,140] Trial 3 finished with value: 0.8890709855715158 and parameters: {'lr': 0.0008946960760299925, 'weight_decay': 0.09835426350244215, 'n_epochs': 28}. Best is trial 0 with value: 0.8991090652013238.\n",
      "[I 2023-07-13 01:10:23,671] Trial 4 finished with value: 0.8809489379478774 and parameters: {'lr': 3.058336490276048e-05, 'weight_decay': 0.09773690750149298, 'n_epochs': 46}. Best is trial 0 with value: 0.8991090652013238.\n",
      "[I 2023-07-13 01:10:26,979] Trial 5 finished with value: 0.8978504557772851 and parameters: {'lr': 0.0007854137055994615, 'weight_decay': 0.04503333466050854, 'n_epochs': 60}. Best is trial 0 with value: 0.8991090652013238.\n",
      "[I 2023-07-13 01:10:27,580] Trial 6 pruned. \n",
      "[I 2023-07-13 01:10:27,646] Trial 7 pruned. \n",
      "[I 2023-07-13 01:10:27,708] Trial 8 pruned. \n",
      "[I 2023-07-13 01:10:29,045] Trial 9 finished with value: 0.8969426502565421 and parameters: {'lr': 0.0017260592606395606, 'weight_decay': 0.04884357261013869, 'n_epochs': 24}. Best is trial 0 with value: 0.8991090652013238.\n",
      "[I 2023-07-13 01:10:33,851] Trial 10 finished with value: 0.9057689835791639 and parameters: {'lr': 0.02259288577469257, 'weight_decay': 0.008096053221881262, 'n_epochs': 87}. Best is trial 10 with value: 0.9057689835791639.\n",
      "[I 2023-07-13 01:10:38,887] Trial 11 finished with value: 0.9090748417365597 and parameters: {'lr': 0.028821993375138803, 'weight_decay': 0.0033653273217578734, 'n_epochs': 91}. Best is trial 11 with value: 0.9090748417365597.\n",
      "[I 2023-07-13 01:10:43,746] Trial 12 pruned. \n",
      "[I 2023-07-13 01:10:47,399] Trial 13 pruned. \n",
      "[I 2023-07-13 01:10:51,061] Trial 14 pruned. \n",
      "[I 2023-07-13 01:10:54,446] Trial 15 pruned. \n",
      "[I 2023-07-13 01:10:54,620] Trial 16 pruned. \n",
      "[I 2023-07-13 01:10:56,247] Trial 17 pruned. \n",
      "[I 2023-07-13 01:10:56,581] Trial 18 finished with value: 0.9101794723480832 and parameters: {'lr': 0.003986295609070618, 'weight_decay': 0.008415817479323039, 'n_epochs': 5}. Best is trial 18 with value: 0.9101794723480832.\n",
      "[I 2023-07-13 01:10:57,097] Trial 19 finished with value: 0.909204719517551 and parameters: {'lr': 0.0038150335751243056, 'weight_decay': 0.011184965982728449, 'n_epochs': 8}. Best is trial 18 with value: 0.9101794723480832.\n",
      "[I 2023-07-13 01:10:57,499] Trial 20 finished with value: 0.9026278158038498 and parameters: {'lr': 0.004401368897545551, 'weight_decay': 0.029376286031948192, 'n_epochs': 7}. Best is trial 18 with value: 0.9101794723480832.\n",
      "[I 2023-07-13 01:10:58,112] Trial 21 finished with value: 0.9097456537806483 and parameters: {'lr': 0.005652119749158033, 'weight_decay': 0.01042978325888968, 'n_epochs': 11}. Best is trial 18 with value: 0.9101794723480832.\n",
      "[I 2023-07-13 01:10:58,399] Trial 22 finished with value: 0.9084375033473655 and parameters: {'lr': 0.004633607845208131, 'weight_decay': 0.012853834467088224, 'n_epochs': 5}. Best is trial 18 with value: 0.9101794723480832.\n",
      "[I 2023-07-13 01:10:58,474] Trial 23 pruned. \n",
      "[I 2023-07-13 01:10:59,387] Trial 24 finished with value: 0.9079193311695961 and parameters: {'lr': 0.007890273948246223, 'weight_decay': 0.011471416875009011, 'n_epochs': 16}. Best is trial 18 with value: 0.9101794723480832.\n",
      "[I 2023-07-13 01:10:59,457] Trial 25 pruned. \n",
      "[I 2023-07-13 01:11:00,344] Trial 26 finished with value: 0.9094028835545271 and parameters: {'lr': 0.006608679212228038, 'weight_decay': 0.010453576575516469, 'n_epochs': 16}. Best is trial 18 with value: 0.9101794723480832.\n",
      "[I 2023-07-13 01:11:01,401] Trial 27 finished with value: 0.9091310774767827 and parameters: {'lr': 0.008930577580946076, 'weight_decay': 0.009030921126710273, 'n_epochs': 19}. Best is trial 18 with value: 0.9101794723480832.\n",
      "[I 2023-07-13 01:11:01,528] Trial 28 pruned. \n",
      "[I 2023-07-13 01:11:01,657] Trial 29 pruned. \n",
      "[I 2023-07-13 01:11:01,726] Trial 30 pruned. \n",
      "[I 2023-07-13 01:11:01,794] Trial 31 pruned. \n",
      "[I 2023-07-13 01:11:01,864] Trial 32 pruned. \n",
      "[I 2023-07-13 01:11:01,991] Trial 33 pruned. \n",
      "[I 2023-07-13 01:11:02,059] Trial 34 pruned. \n",
      "[I 2023-07-13 01:11:02,130] Trial 35 pruned. \n",
      "[I 2023-07-13 01:11:02,314] Trial 36 pruned. \n",
      "[I 2023-07-13 01:11:02,384] Trial 37 pruned. \n",
      "[I 2023-07-13 01:11:02,454] Trial 38 pruned. \n",
      "[I 2023-07-13 01:11:02,579] Trial 39 pruned. \n",
      "[I 2023-07-13 01:11:02,647] Trial 40 pruned. \n",
      "[I 2023-07-13 01:11:03,887] Trial 41 finished with value: 0.909598369699112 and parameters: {'lr': 0.010788173142558168, 'weight_decay': 0.007702700445791172, 'n_epochs': 22}. Best is trial 18 with value: 0.9101794723480832.\n",
      "[I 2023-07-13 01:11:05,380] Trial 42 finished with value: 0.911419336525381 and parameters: {'lr': 0.005192374547764227, 'weight_decay': 0.007800520247860465, 'n_epochs': 24}. Best is trial 42 with value: 0.911419336525381.\n",
      "[I 2023-07-13 01:11:06,663] Trial 43 finished with value: 0.9133407243163343 and parameters: {'lr': 0.005744049903085439, 'weight_decay': 0.0051557979430827666, 'n_epochs': 22}. Best is trial 43 with value: 0.9133407243163343.\n",
      "[I 2023-07-13 01:11:06,844] Trial 44 pruned. \n",
      "[I 2023-07-13 01:11:08,208] Trial 45 finished with value: 0.9105637499062738 and parameters: {'lr': 0.011923430530737831, 'weight_decay': 0.006120726723630798, 'n_epochs': 24}. Best is trial 43 with value: 0.9133407243163343.\n",
      "[I 2023-07-13 01:11:08,281] Trial 46 pruned. \n",
      "[I 2023-07-13 01:11:08,412] Trial 47 pruned. \n",
      "[I 2023-07-13 01:11:10,928] Trial 48 finished with value: 0.9103066722366826 and parameters: {'lr': 0.013897801821085165, 'weight_decay': 0.006131572272221251, 'n_epochs': 45}. Best is trial 43 with value: 0.9133407243163343.\n",
      "[I 2023-07-13 01:11:11,110] Trial 49 pruned. \n",
      "[I 2023-07-13 01:11:13,857] Trial 50 finished with value: 0.9115371637906102 and parameters: {'lr': 0.0144044269317324, 'weight_decay': 0.004653040165576182, 'n_epochs': 48}. Best is trial 43 with value: 0.9133407243163343.\n",
      "[I 2023-07-13 01:11:16,421] Trial 51 finished with value: 0.910773964459012 and parameters: {'lr': 0.014191689142561923, 'weight_decay': 0.0055734163723713094, 'n_epochs': 46}. Best is trial 43 with value: 0.9133407243163343.\n",
      "[I 2023-07-13 01:11:19,219] Trial 52 finished with value: 0.9120995211928405 and parameters: {'lr': 0.01613488934299484, 'weight_decay': 0.003766201831402782, 'n_epochs': 50}. Best is trial 43 with value: 0.9133407243163343.\n",
      "[I 2023-07-13 01:11:22,462] Trial 53 finished with value: 0.9133514358859004 and parameters: {'lr': 0.02022643382007056, 'weight_decay': 0.0020457544714876227, 'n_epochs': 57}. Best is trial 53 with value: 0.9133514358859004.\n",
      "[I 2023-07-13 01:11:25,998] Trial 54 finished with value: 0.9130983750548967 and parameters: {'lr': 0.021165564831593833, 'weight_decay': 0.000471083213017795, 'n_epochs': 63}. Best is trial 53 with value: 0.9133514358859004.\n",
      "[I 2023-07-13 01:11:29,350] Trial 55 finished with value: 0.9138281007316003 and parameters: {'lr': 0.02165786704594162, 'weight_decay': 0.0007010658799301095, 'n_epochs': 59}. Best is trial 55 with value: 0.9138281007316003.\n",
      "[I 2023-07-13 01:11:33,191] Trial 56 finished with value: 0.9133514358859005 and parameters: {'lr': 0.02036108012107132, 'weight_decay': 0.0005387305305557975, 'n_epochs': 68}. Best is trial 55 with value: 0.9138281007316003.\n",
      "[I 2023-07-13 01:11:37,080] Trial 57 finished with value: 0.91326574332937 and parameters: {'lr': 0.025268784289775633, 'weight_decay': 0.0005834233895375371, 'n_epochs': 69}. Best is trial 55 with value: 0.9138281007316003.\n",
      "[I 2023-07-13 01:11:41,142] Trial 58 finished with value: 0.9108583180693466 and parameters: {'lr': 0.022685891885464635, 'weight_decay': 0.00023522080990716354, 'n_epochs': 70}. Best is trial 55 with value: 0.9138281007316003.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-13 01:11:43,751] Trial 59 pruned. \n",
      "[I 2023-07-13 01:11:43,828] Trial 60 pruned. \n",
      "[I 2023-07-13 01:11:48,008] Trial 61 finished with value: 0.9107324571269428 and parameters: {'lr': 0.023175484388767268, 'weight_decay': 0.002205446703355569, 'n_epochs': 75}. Best is trial 55 with value: 0.9138281007316003.\n",
      "[I 2023-07-13 01:11:51,243] Trial 62 finished with value: 0.9128024679456281 and parameters: {'lr': 0.019264712315203197, 'weight_decay': 0.002665336969567456, 'n_epochs': 58}. Best is trial 55 with value: 0.9138281007316003.\n",
      "[I 2023-07-13 01:11:51,313] Trial 63 pruned. \n",
      "[I 2023-07-13 01:11:51,390] Trial 64 pruned. \n",
      "[I 2023-07-13 01:11:51,460] Trial 65 pruned. \n",
      "[I 2023-07-13 01:11:54,898] Trial 66 finished with value: 0.9131599665799028 and parameters: {'lr': 0.019261345426658225, 'weight_decay': 0.0024075967327274687, 'n_epochs': 61}. Best is trial 55 with value: 0.9138281007316003.\n",
      "[I 2023-07-13 01:11:56,813] Trial 67 pruned. \n",
      "[I 2023-07-13 01:11:56,884] Trial 68 pruned. \n",
      "[I 2023-07-13 01:11:56,953] Trial 69 pruned. \n",
      "[I 2023-07-13 01:11:57,023] Trial 70 pruned. \n",
      "[I 2023-07-13 01:11:59,759] Trial 71 pruned. \n",
      "[I 2023-07-13 01:12:03,078] Trial 72 finished with value: 0.9137531197446362 and parameters: {'lr': 0.008638769664287933, 'weight_decay': 0.0031013074596666084, 'n_epochs': 60}. Best is trial 55 with value: 0.9138281007316003.\n",
      "[I 2023-07-13 01:12:03,259] Trial 73 pruned. \n",
      "[I 2023-07-13 01:12:03,385] Trial 74 pruned. \n",
      "[I 2023-07-13 01:12:05,007] Trial 75 pruned. \n",
      "[I 2023-07-13 01:12:05,080] Trial 76 pruned. \n",
      "[I 2023-07-13 01:12:05,385] Trial 77 pruned. \n",
      "[I 2023-07-13 01:12:05,567] Trial 78 pruned. \n",
      "[I 2023-07-13 01:12:05,645] Trial 79 pruned. \n",
      "[I 2023-07-13 01:12:05,715] Trial 80 pruned. \n",
      "[I 2023-07-13 01:12:09,017] Trial 81 finished with value: 0.9132041518043639 and parameters: {'lr': 0.01107313323355773, 'weight_decay': 0.003181134463375555, 'n_epochs': 59}. Best is trial 55 with value: 0.9138281007316003.\n",
      "[I 2023-07-13 01:12:09,303] Trial 82 pruned. \n",
      "[I 2023-07-13 01:12:12,348] Trial 83 finished with value: 0.9140128753066187 and parameters: {'lr': 0.009355529922449392, 'weight_decay': 0.002450346777927647, 'n_epochs': 54}. Best is trial 83 with value: 0.9140128753066187.\n",
      "[I 2023-07-13 01:12:12,419] Trial 84 pruned. \n",
      "[I 2023-07-13 01:12:15,722] Trial 85 finished with value: 0.9136781387576721 and parameters: {'lr': 0.010579299882303233, 'weight_decay': 0.0027519677797434687, 'n_epochs': 59}. Best is trial 83 with value: 0.9140128753066187.\n",
      "[I 2023-07-13 01:12:15,788] Trial 86 pruned. \n",
      "[I 2023-07-13 01:12:15,859] Trial 87 pruned. \n",
      "[I 2023-07-13 01:12:15,941] Trial 88 pruned. \n",
      "[I 2023-07-13 01:12:16,088] Trial 89 pruned. \n",
      "[I 2023-07-13 01:12:17,098] Trial 90 pruned. \n",
      "[I 2023-07-13 01:12:20,695] Trial 91 finished with value: 0.9139700290283534 and parameters: {'lr': 0.012240827665808926, 'weight_decay': 0.002199182533048305, 'n_epochs': 61}. Best is trial 83 with value: 0.9140128753066187.\n",
      "[I 2023-07-13 01:12:23,848] Trial 92 finished with value: 0.913522820998961 and parameters: {'lr': 0.012813776105306008, 'weight_decay': 0.002597469969129403, 'n_epochs': 55}. Best is trial 83 with value: 0.9140128753066187.\n",
      "[I 2023-07-13 01:12:23,921] Trial 93 pruned. \n",
      "[I 2023-07-13 01:12:24,004] Trial 94 pruned. \n",
      "[I 2023-07-13 01:12:24,348] Trial 95 pruned. \n",
      "[I 2023-07-13 01:12:28,105] Trial 96 finished with value: 0.9142820034919718 and parameters: {'lr': 0.012585282493342691, 'weight_decay': 0.0018828840561176574, 'n_epochs': 65}. Best is trial 96 with value: 0.9142820034919718.\n",
      "[I 2023-07-13 01:12:28,176] Trial 97 pruned. \n",
      "[I 2023-07-13 01:12:28,300] Trial 98 pruned. \n",
      "[I 2023-07-13 01:12:30,919] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  59\n",
      "  Number of complete trials:  41\n",
      "Best trial:\n",
      "  Value:  0.9142820034919718\n",
      "  Params: \n",
      "    lr: 0.012585282493342691\n",
      "    weight_decay: 0.0018828840561176574\n",
      "    n_epochs: 65\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
